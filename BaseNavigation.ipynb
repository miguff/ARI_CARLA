{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('F:\\CARLA\\Windows\\CARLA_0.9.15\\PythonAPI\\carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "world = client.get_world()\n",
    "\n",
    "blueprints = [bp for bp in world.get_blueprint_library().filter('*')]\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destroy():#Destroying the existing things\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawPointsFor30Sec(world, spawn_points):\n",
    "    drawn_points = []\n",
    "    for index, waypoint in enumerate(spawn_points):\n",
    "        # Draw a string with an ID at the location of each spawn point\n",
    "        point_id = f'ID: {index}'\n",
    "        point = world.debug.draw_string(\n",
    "            waypoint.location,\n",
    "            point_id,\n",
    "            draw_shadow=False,\n",
    "            color=carla.Color(r=255, g=255, b=255),\n",
    "            life_time=30,  # Set to 0 to make it persist indefinitely\n",
    "            persistent_lines=True\n",
    "        )\n",
    "        drawn_points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawPointsFor30Sec(world, spawn_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the bicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicycleorigin():\n",
    "    global bicycle\n",
    "    bicycle_bp = world.get_blueprint_library().filter('*crossbike*')\n",
    "    bicycle_start_point = spawn_points[1]\n",
    "\n",
    "    bicycle = world.try_spawn_actor(bicycle_bp[0], bicycle_start_point)\n",
    "    bicyclepos = carla.Transform(bicycle_start_point.location + carla.Location(x=-3, y=3.5))\n",
    "    bicycle.set_transform(bicyclepos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carorigin():\n",
    "    global vehicle, vehicle_start_point\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*mini*')\n",
    "    vehicle_start_point = spawn_points[94]\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], vehicle_start_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Car speed and etc specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = None\n",
    "bicycle = None\n",
    "vehicle_start_point = None\n",
    "destroy()\n",
    "bicycleorigin()\n",
    "carorigin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFERRED_SPEED = 30 #km/h\n",
    "SPEED_THRESHOLD = 2 #When we close to the required speed, it drops the throttle\n",
    "MAX_STEER_DEGREES = 40\n",
    "\n",
    "#Params for displaying text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "org = (30, 30) # This is for current speed\n",
    "org2 = (30, 50) #This is for future steering angle\n",
    "org3 = (30, 70) #this is for future telemetry\n",
    "org4 = (30, 90) #this is for future telemetry\n",
    "org5 = (30, 110) #this is for future telemetry\n",
    "fontscale = 0.5\n",
    "color = (255, 255, 255)\n",
    "tickness = 1\n",
    "\n",
    "def maintain_speed(s: float) -> float:\n",
    "    \n",
    "    if s >= PREFERRED_SPEED:\n",
    "        return 0\n",
    "    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n",
    "        return 0.8\n",
    "    else:\n",
    "        return 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the collision detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_collision(event):\n",
    "    # Extract collision data\n",
    "    global collision_happened\n",
    "    other_actor = event.other_actor\n",
    "    impulse = event.normal_impulse\n",
    "    collision_location = event.transform.location\n",
    "    print(f\"Collision with {other_actor.type_id}\")\n",
    "    print(f\"Impulse: {impulse}\")\n",
    "    print(f\"Location: {collision_location}\")\n",
    "    collision_happened = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_detector_bp = world.get_blueprint_library().find('sensor.other.collision')\n",
    "collision_sensor = world.spawn_actor(\n",
    "        collision_detector_bp,\n",
    "        carla.Transform(),\n",
    "        attach_to=vehicle\n",
    "    )\n",
    "collision_sensor.listen(lambda event: process_collision(event))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the GlobalRoutePlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetid = 27\n",
    "targetPoint = spawn_points[targetid]\n",
    "\n",
    "point_A = vehicle_start_point.location\n",
    "point_B = targetPoint.location\n",
    "\n",
    "\n",
    "sampling_resolution = 1\n",
    "grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "\n",
    "route = grp.trace_route(point_A, point_B)\n",
    "for waypoint in route:\n",
    "    world.debug.draw_string(waypoint[0].transform.location, '^', draw_shadow=False,\n",
    "                            color=carla.Color(r=0, g=0, b=255), life_time=600.0,\n",
    "                            persistent_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between(v1, v2):\n",
    "    return math.degrees(np.arctan2(v1[1], v1[0]) - np.arctan2(v2[1], v2[0]))\n",
    "\n",
    "def get_angle(car, wp):\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "\n",
    "\n",
    "    #vector to waypoint\n",
    "    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "\n",
    "\n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = angle_between((x,y), (car_vector.x, car_vector.y))\n",
    "\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Camera sensor and the YOLO algoritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "#setup the camera\n",
    "CAMERA_POS_Z = 1.5 \n",
    "CAMERA1_POS_X = 0\n",
    "CAMERA2_POS_X = 1\n",
    "CAMERA1_POS_Y = 0.5\n",
    "CAMERA2_POS_Y = 0.1\n",
    "\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.14 on Windows\n",
    "camera_bp.set_attribute('image_size_y', '360')\n",
    "\n",
    "\n",
    "camera1_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA1_POS_X, y = CAMERA1_POS_Y), carla.Rotation(yaw=90))\n",
    "camera1 = world.spawn_actor(camera_bp,camera1_init_trans,attach_to=vehicle)\n",
    "\n",
    "camera2_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA2_POS_X, y = CAMERA1_POS_Y), carla.Rotation(yaw=90))\n",
    "camera2 = world.spawn_actor(camera_bp,camera2_init_trans,attach_to=vehicle)\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "camera1_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "camera2_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "# this actually opens a live stream from the camera\n",
    "camera1.listen(lambda image: camera_callback(image,camera1_data))\n",
    "camera2.listen(lambda image: camera_callback(image,camera2_data))\n",
    "model = YOLO(\"best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def match_bicycles_between_left_right(bicycles_left: list, bicycles_right: list):\n",
    "    image_w = 640  # Image width\n",
    "    fov = 90  # Field of view in degrees\n",
    "    baseline = abs(CAMERA1_POS_X-CAMERA2_POS_X)  # Baseline distance in meters\n",
    "    focal_length = image_w / (2 * math.tan(math.radians(fov / 2)))  # Focal length in pixels\n",
    "\n",
    "    \n",
    "    y_threshold = 20  # pixels, adjust based on image scale\n",
    "    matched_bicycles_with_distances = []\n",
    "\n",
    "    for left_bicycle in bicycles_left:\n",
    "        left_x, left_y = left_bicycle\n",
    "        closest_bicycle = None\n",
    "        min_dist = float('inf')\n",
    "\n",
    "        for right_bicycle in bicycles_right:\n",
    "            right_x, right_y = right_bicycle\n",
    "            # Check if the y-coordinates are similar\n",
    "            if abs(left_y - right_y) < y_threshold:\n",
    "                # Calculate the distance (disparity)\n",
    "                dist = abs(left_x - right_x)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_bicycle = right_bicycle\n",
    "\n",
    "        # If a match was found, calculate depth and add to list\n",
    "        if closest_bicycle:\n",
    "            right_x, _ = closest_bicycle\n",
    "            disparity = abs(left_x - right_x)\n",
    "            depth = (focal_length * baseline) / disparity if disparity != 0 else float('inf')\n",
    "            matched_bicycles_with_distances.append((left_bicycle, depth))\n",
    "\n",
    "    return matched_bicycles_with_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 83.1ms\n",
      "Speed: 1.0ms preprocess, 83.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 65.9ms\n",
      "Speed: 2.0ms preprocess, 65.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 65.8ms\n",
      "Speed: 1.0ms preprocess, 65.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 65.9ms\n",
      "Speed: 1.5ms preprocess, 65.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=0.000000, z=0.000000)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=-0.000000, z=-0.002528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 110.8ms\n",
      "Speed: 1.0ms preprocess, 110.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 72.3ms\n",
      "Speed: 5.0ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.7ms\n",
      "Speed: 2.0ms preprocess, 64.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=-0.000000, z=-0.001107)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=-0.000000, z=-0.000491)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 65.0ms\n",
      "Speed: 3.0ms preprocess, 65.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 65.2ms\n",
      "Speed: 1.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 69.7ms\n",
      "Speed: 2.0ms preprocess, 69.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.2ms\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 4.0\n",
      "Speed vector: Vector3D(x=1.208567, y=0.003360, z=-0.000901)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 7.0\n",
      "Speed vector: Vector3D(x=1.853514, y=0.005155, z=0.000244)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 66.9ms\n",
      "Speed: 2.5ms preprocess, 66.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.8ms\n",
      "Speed: 2.0ms preprocess, 64.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.1ms\n",
      "Speed: 2.0ms preprocess, 63.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 8.0\n",
      "Speed vector: Vector3D(x=2.338239, y=0.006128, z=-0.001090)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 10.0\n",
      "Speed vector: Vector3D(x=2.870662, y=0.007746, z=0.000486)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 66.5ms\n",
      "Speed: 1.5ms preprocess, 66.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.6ms\n",
      "Speed: 2.0ms preprocess, 62.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 12.0\n",
      "Speed vector: Vector3D(x=3.382283, y=0.009277, z=0.000471)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 14.0\n",
      "Speed vector: Vector3D(x=3.945885, y=0.010893, z=0.000690)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 61.7ms\n",
      "Speed: 1.0ms preprocess, 61.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.3ms\n",
      "Speed: 2.0ms preprocess, 64.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.7ms\n",
      "Speed: 1.0ms preprocess, 62.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 16.0\n",
      "Speed vector: Vector3D(x=4.573461, y=0.012706, z=-0.000121)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 19.0\n",
      "Speed vector: Vector3D(x=5.149872, y=0.014316, z=0.002213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 65.6ms\n",
      "Speed: 1.0ms preprocess, 65.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.0ms\n",
      "Speed: 2.0ms preprocess, 63.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 20.0\n",
      "Speed vector: Vector3D(x=5.566742, y=0.015704, z=-0.000330)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 21.0\n",
      "Speed vector: Vector3D(x=5.876956, y=0.016135, z=-0.000307)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 62.1ms\n",
      "Speed: 2.5ms preprocess, 62.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 61.6ms\n",
      "Speed: 1.0ms preprocess, 61.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 61.7ms\n",
      "Speed: 2.0ms preprocess, 61.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 61.1ms\n",
      "Speed: 2.0ms preprocess, 61.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 22.0\n",
      "Speed vector: Vector3D(x=6.034280, y=0.016210, z=-0.000090)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 26.0\n",
      "Speed vector: Vector3D(x=7.222726, y=0.021886, z=-0.000008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.3ms\n",
      "Speed: 3.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.7ms\n",
      "Speed: 1.5ms preprocess, 62.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 61.1ms\n",
      "Speed: 2.0ms preprocess, 61.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 29.0\n",
      "Speed vector: Vector3D(x=8.087277, y=0.022852, z=0.000003)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 31.0\n",
      "Speed vector: Vector3D(x=8.506780, y=0.023651, z=0.000002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.1ms\n",
      "Speed: 2.0ms preprocess, 62.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 91.7ms\n",
      "Speed: 1.0ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 30.0\n",
      "Speed vector: Vector3D(x=8.366262, y=0.023070, z=0.000001)\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 26.0\n",
      "Speed vector: Vector3D(x=7.106126, y=0.018796, z=-0.000001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Bicycle, 65.1ms\n",
      "Speed: 1.0ms preprocess, 65.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 63.6ms\n",
      "Speed: 2.0ms preprocess, 63.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 62.1ms\n",
      "Speed: 2.5ms preprocess, 62.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 61.2ms\n",
      "Speed: 2.5ms preprocess, 61.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 22.0\n",
      "Speed vector: Vector3D(x=6.007004, y=0.016513, z=0.000000)\n",
      "Distance: 6.96m\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 21.0\n",
      "Speed vector: Vector3D(x=5.879153, y=0.109330, z=0.000000)\n",
      "Distance: 4.21m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Bicycle, 63.6ms\n",
      "Speed: 1.0ms preprocess, 63.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 64.1ms\n",
      "Speed: 1.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 62.6ms\n",
      "Speed: 2.0ms preprocess, 62.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 61.7ms\n",
      "Speed: 2.0ms preprocess, 61.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 22.0\n",
      "Speed vector: Vector3D(x=6.126675, y=0.291016, z=0.000001)\n",
      "Distance: 3.60m\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 24.0\n",
      "Speed vector: Vector3D(x=6.679557, y=0.612574, z=0.000000)\n",
      "Distance: 3.27m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Bicycle, 69.4ms\n",
      "Speed: 1.0ms preprocess, 69.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 64.6ms\n",
      "Speed: 1.5ms preprocess, 64.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 63.1ms\n",
      "Speed: 2.0ms preprocess, 63.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bicycles, 60.6ms\n",
      "Speed: 2.0ms preprocess, 60.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 29.0\n",
      "Speed vector: Vector3D(x=7.832559, y=1.229624, z=-0.000001)\n",
      "Distance: 2.99m\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 30.0\n",
      "Speed vector: Vector3D(x=7.992517, y=2.067258, z=-0.000001)\n",
      "Distance: 4.38m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Bicycle, 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 62.1ms\n",
      "Speed: 2.0ms preprocess, 62.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 62.3ms\n",
      "Speed: 1.0ms preprocess, 62.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 62.1ms\n",
      "Speed: 2.0ms preprocess, 62.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 29.0\n",
      "Speed vector: Vector3D(x=7.519246, y=2.925581, z=-0.000001)\n",
      "Distance: 2.62m\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 28.0\n",
      "Speed vector: Vector3D(x=6.638568, y=3.879109, z=-0.000001)\n",
      "Distance: 1.77m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Bicycle, 65.1ms\n",
      "Speed: 1.5ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 65.6ms\n",
      "Speed: 1.0ms preprocess, 65.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collision with vehicle.bh.crossbike\n",
      "Impulse: Vector3D(x=19.548450, y=-31.641777, z=-22.643250)\n",
      "Location: Location(x=-56.016224, y=30.061197, z=0.042887)\n"
     ]
    }
   ],
   "source": [
    "curr_wp = 5\n",
    "collision_happened = False\n",
    "quitLoop = False\n",
    "\n",
    "while curr_wp<len(route)-1:\n",
    "    world.tick()\n",
    "    \n",
    "    while vehicle.get_transform().location.distance(route[curr_wp][0].transform.location) < 5:\n",
    "        curr_wp += 1\n",
    "\n",
    "    #Setup the object detection\n",
    "    frame1 = camera1_data['image']\n",
    "    frame2 = camera2_data['image']\n",
    "\n",
    "    frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGRA2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGRA2GRAY)\n",
    "    # Convert RGB image from BGRA to BGR\n",
    "    frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGRA2BGR)\n",
    "    frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGRA2BGR)\n",
    "    #computeDepthMapSGBM(frame1_gray, frame2_gray)\n",
    "    # Run the object detection model on the RGB frame\n",
    "    results_left = model(frame1)\n",
    "    results_right = model(frame2)\n",
    "    \n",
    "    bicycles_left = []\n",
    "    bicycles_right = []\n",
    "\n",
    "\n",
    "\n",
    "    for result in results_left:\n",
    "        for box in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)  # x-center of the bicycle\n",
    "            center_y = int((y1 + y2) / 2)  # y-center of the bicycle\n",
    "            bicycles_left.append((center_x, center_y))\n",
    "            conf = box.conf[0]            # Confidence score\n",
    "            cls = box.cls[0]\n",
    "            cv2.rectangle(frame1, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(frame1, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            #break\n",
    "              # Bounding box coordinates\n",
    "    \n",
    "    for result in results_right:\n",
    "        for box2 in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box2.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "            bicycles_right.append((center_x, center_y))\n",
    "            conf = box2.conf[0]            # Confidence score\n",
    "            cls = box2.cls[0]\n",
    "\n",
    "            cv2.rectangle(frame2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(frame2, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    matched_bicycles_with_distances = match_bicycles_between_left_right(bicycles_left, bicycles_right)\n",
    "    # Display distance for each matched bicycle on the left frame\n",
    "    for (left_bicycle, distance) in matched_bicycles_with_distances:\n",
    "        left_x, left_y = left_bicycle\n",
    "        distance_label = f\"Distance: {distance:.2f}m\"\n",
    "        cv2.putText(frame1, distance_label, (left_x, left_y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "\n",
    "    #Estimate the throttle \n",
    "    predicted_angle = get_angle(vehicle, route[curr_wp][0])\n",
    "    v = vehicle.get_velocity()\n",
    "    speed = round(3.6*math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n",
    "    estimated_throttle = maintain_speed(speed)\n",
    "\n",
    "\n",
    "    #Setup the steering angle\n",
    "    if predicted_angle < -300:\n",
    "        predicted_angle = predicted_angle+360\n",
    "    elif predicted_angle > 300:\n",
    "        predicted_angle = predicted_angle - 360\n",
    "    steering_angle = predicted_angle\n",
    "\n",
    "    if predicted_angle < -MAX_STEER_DEGREES:\n",
    "        steering_angle = -MAX_STEER_DEGREES\n",
    "    elif predicted_angle>MAX_STEER_DEGREES:\n",
    "        steering_angle = MAX_STEER_DEGREES\n",
    "    \n",
    "    steering_angle = steering_angle/75\n",
    "\n",
    "\n",
    "    #Apply the vehicle control to each of the two vehicles\n",
    "    bicycle.apply_control(carla.VehicleControl(throttle=1))\n",
    "    vehicle.apply_control(carla.VehicleControl(throttle = estimated_throttle, steer = steering_angle))\n",
    "    \n",
    "    speed_text = f\"{speed} km/h\"\n",
    "    cv2.putText(frame1, speed_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Camera1',frame1)\n",
    "    cv2.imshow(\"camera2\", frame2)\n",
    "    # Exit loop on 'q' key press\n",
    "    if cv2.waitKey(1) == ord('q') or collision_happened:\n",
    "        break\n",
    "\n",
    "    print('------------------')\n",
    "    print('These are the parameters that we might need')\n",
    "    print(f\"speed: {speed}\")\n",
    "    print(f\"Speed vector: {v}\")\n",
    "    try:\n",
    "        print(distance_label)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "    #Check if a collision happenned\n",
    "    if collision_happened:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows() \n",
    "vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "bicycle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "destroy()\n",
    "bicycleorigin()\n",
    "carorigin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
