{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('F:\\CARLA\\Windows\\CARLA_0.9.15\\PythonAPI\\carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "world = client.get_world()\n",
    "\n",
    "blueprints = [bp for bp in world.get_blueprint_library().filter('*')]\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destroy():#Destroying the existing things\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def DrawPointsFor30Sec(world, spawn_points):\n",
    "    drawn_points = []\n",
    "    for index, waypoint in enumerate(spawn_points):\n",
    "        # Draw a string with an ID at the location of each spawn point\n",
    "        point_id = f'ID: {index}'\n",
    "        point = world.debug.draw_string(\n",
    "            waypoint.location,\n",
    "            point_id,\n",
    "            draw_shadow=False,\n",
    "            color=carla.Color(r=255, g=255, b=255),\n",
    "            life_time=30,  # Set to 0 to make it persist indefinitely\n",
    "            persistent_lines=True\n",
    "        )\n",
    "        drawn_points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawPointsFor30Sec(world, spawn_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the bicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicycleorigin():\n",
    "    global bicycle\n",
    "    bicycle_bp = world.get_blueprint_library().filter('*crossbike*')\n",
    "    bicycle_start_point = spawn_points[1]\n",
    "\n",
    "    bicycle = world.try_spawn_actor(bicycle_bp[0], bicycle_start_point)\n",
    "    bicyclepos = carla.Transform(bicycle_start_point.location + carla.Location(x=-3, y=3.5))\n",
    "    bicycle.set_transform(bicyclepos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carorigin():\n",
    "    global vehicle, vehicle_start_point\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*mini*')\n",
    "    vehicle_start_point = spawn_points[94]\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], vehicle_start_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Car speed and etc specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = None\n",
    "bicycle = None\n",
    "vehicle_start_point = None\n",
    "destroy()\n",
    "bicycleorigin()\n",
    "carorigin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFERRED_SPEED = 30 #km/h\n",
    "SPEED_THRESHOLD = 2 #When we close to the required speed, it drops the throttle\n",
    "MAX_STEER_DEGREES = 40\n",
    "\n",
    "#Params for displaying text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "org = (30, 30) # This is for current speed\n",
    "org2 = (30, 50) #This is for future steering angle\n",
    "org3 = (30, 70) #this is for future telemetry\n",
    "org4 = (30, 90) #this is for future telemetry\n",
    "org5 = (30, 110) #this is for future telemetry\n",
    "fontscale = 0.5\n",
    "color = (255, 255, 255)\n",
    "tickness = 1\n",
    "\n",
    "def maintain_speed(s: float) -> float:\n",
    "    \n",
    "    if s >= PREFERRED_SPEED:\n",
    "        return 0\n",
    "    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n",
    "        return 0.8\n",
    "    else:\n",
    "        return 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the collision detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_collision(event):\n",
    "    # Extract collision data\n",
    "    global collision_happened\n",
    "    other_actor = event.other_actor\n",
    "    impulse = event.normal_impulse\n",
    "    collision_location = event.transform.location\n",
    "    print(f\"Collision with {other_actor.type_id}\")\n",
    "    print(f\"Impulse: {impulse}\")\n",
    "    print(f\"Location: {collision_location}\")\n",
    "    collision_happened = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_detector_bp = world.get_blueprint_library().find('sensor.other.collision')\n",
    "collision_sensor = world.spawn_actor(\n",
    "        collision_detector_bp,\n",
    "        carla.Transform(),\n",
    "        attach_to=vehicle\n",
    "    )\n",
    "collision_sensor.listen(lambda event: process_collision(event))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the GlobalRoutePlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetid = 27\n",
    "targetPoint = spawn_points[targetid]\n",
    "\n",
    "point_A = vehicle_start_point.location\n",
    "point_B = targetPoint.location\n",
    "\n",
    "\n",
    "sampling_resolution = 1\n",
    "grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "\n",
    "route = grp.trace_route(point_A, point_B)\n",
    "for waypoint in route:\n",
    "    world.debug.draw_string(waypoint[0].transform.location, '^', draw_shadow=False,\n",
    "                            color=carla.Color(r=0, g=0, b=255), life_time=600.0,\n",
    "                            persistent_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between(v1, v2):\n",
    "    return math.degrees(np.arctan2(v1[1], v1[0]) - np.arctan2(v2[1], v2[0]))\n",
    "\n",
    "def get_angle(car, wp):\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "\n",
    "\n",
    "    #vector to waypoint\n",
    "    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "\n",
    "\n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = angle_between((x,y), (car_vector.x, car_vector.y))\n",
    "\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Camera sensor and the YOLO algoritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "#setup the camera\n",
    "CAMERA_POS_Z = 1.5 \n",
    "CAMERA1_POS_X = 0\n",
    "CAMERA2_POS_X = 1\n",
    "CAMERA1_POS_Y = 0.5\n",
    "CAMERA2_POS_Y = 1.5\n",
    "\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.14 on Windows\n",
    "camera_bp.set_attribute('image_size_y', '360')\n",
    "\n",
    "\n",
    "rightcamera1_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA1_POS_X, y = CAMERA1_POS_Y), carla.Rotation(yaw=90))\n",
    "rightcamera1 = world.spawn_actor(camera_bp,rightcamera1_init_trans,attach_to=vehicle)\n",
    "\n",
    "rightcamera2_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA2_POS_X, y = CAMERA1_POS_Y), carla.Rotation(yaw=90))\n",
    "rightcamera2 = world.spawn_actor(camera_bp,rightcamera2_init_trans,attach_to=vehicle)\n",
    "\n",
    "frontcamera1_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA1_POS_X, y = CAMERA1_POS_Y))\n",
    "frontcamera1 = world.spawn_actor(camera_bp,frontcamera1_init_trans,attach_to=vehicle)\n",
    "\n",
    "frontcamera2_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA1_POS_X, y = CAMERA2_POS_Y))\n",
    "frontcamera2 = world.spawn_actor(camera_bp,frontcamera2_init_trans,attach_to=vehicle)\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "rightcamera1_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "rightcamera2_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "frontcamera1_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "frontcamera2_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "# this actually opens a live stream from the camera\n",
    "rightcamera1.listen(lambda image: camera_callback(image,rightcamera1_data))\n",
    "rightcamera2.listen(lambda image: camera_callback(image,rightcamera2_data))\n",
    "frontcamera1.listen(lambda image: camera_callback(image,frontcamera1_data))\n",
    "frontcamera2.listen(lambda image: camera_callback(image,frontcamera2_data))\n",
    "model = YOLO(\"best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def match_bicycles_between_left_right(bicycles_left: list, bicycles_right: list):\n",
    "    image_w = 640  # Image width\n",
    "    fov = 90  # Field of view in degrees\n",
    "    baseline = 1  # Baseline distance in meters\n",
    "    focal_length = image_w / (2 * math.tan(math.radians(fov / 2)))  # Focal length in pixels\n",
    "\n",
    "    \n",
    "    y_threshold = 20  # pixels, adjust based on image scale\n",
    "    matched_bicycles_with_distances = []\n",
    "\n",
    "    for left_bicycle in bicycles_left:\n",
    "        left_x, left_y = left_bicycle\n",
    "        closest_bicycle = None\n",
    "        min_dist = float('inf')\n",
    "\n",
    "        for right_bicycle in bicycles_right:\n",
    "            right_x, right_y = right_bicycle\n",
    "            # Check if the y-coordinates are similar\n",
    "            if abs(left_y - right_y) < y_threshold:\n",
    "                # Calculate the distance (disparity)\n",
    "                dist = abs(left_x - right_x)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_bicycle = right_bicycle\n",
    "\n",
    "        # If a match was found, calculate depth and add to list\n",
    "        if closest_bicycle:\n",
    "            right_x, _ = closest_bicycle\n",
    "            disparity = abs(left_x - right_x)\n",
    "            depth = (focal_length * baseline) / disparity if disparity != 0 else float('inf')\n",
    "            matched_bicycles_with_distances.append((left_bicycle, depth))\n",
    "\n",
    "    return matched_bicycles_with_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 125.8ms\n",
      "Speed: 3.0ms preprocess, 125.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 73.2ms\n",
      "Speed: 2.0ms preprocess, 73.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 62.4ms\n",
      "Speed: 2.0ms preprocess, 62.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 69.7ms\n",
      "Speed: 2.0ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.41m\n",
      "Average distance: 9.411764705882355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=0.000000, z=0.000000)\n",
      "Distance (front camera): 9.41m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 65.9ms\n",
      "Speed: 2.0ms preprocess, 65.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 71.6ms\n",
      "Speed: 2.5ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.2ms\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 66.0ms\n",
      "Speed: 1.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.41m\n",
      "Average distance: 9.411764705882355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=-0.000000, z=-0.000062)\n",
      "Distance (front camera): 9.41m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 67.7ms\n",
      "Speed: 1.0ms preprocess, 67.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 67.7ms\n",
      "Speed: 1.0ms preprocess, 67.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 72.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.41m\n",
      "Average distance: 9.411764705882355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 1.0\n",
      "Speed vector: Vector3D(x=0.317032, y=0.000852, z=-0.000098)\n",
      "Distance (front camera): 9.41m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 105.9ms\n",
      "Speed: 1.0ms preprocess, 105.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.6ms\n",
      "Speed: 2.0ms preprocess, 64.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 65.2ms\n",
      "Speed: 1.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.41m\n",
      "Average distance: 9.411764705882355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 8.0\n",
      "Speed vector: Vector3D(x=2.265567, y=0.006403, z=0.000231)\n",
      "Distance (front camera): 9.41m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 Bicycles, 68.7ms\n",
      "Speed: 1.0ms preprocess, 68.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 67.1ms\n",
      "Speed: 2.4ms preprocess, 67.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.4ms\n",
      "Speed: 2.0ms preprocess, 62.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 8.65m\n",
      "Average distance: 8.648648648648651\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 12.0\n",
      "Speed vector: Vector3D(x=3.216740, y=0.008851, z=0.000302)\n",
      "Distance (front camera): 8.65m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 70.6ms\n",
      "Speed: 2.0ms preprocess, 70.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 69.5ms\n",
      "Speed: 2.5ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 66.2ms\n",
      "Speed: 2.0ms preprocess, 66.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 8.00m\n",
      "Average distance: 8.000000000000002\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 16.0\n",
      "Speed vector: Vector3D(x=4.507479, y=0.012623, z=-0.000371)\n",
      "Distance (front camera): 8.00m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 65.1ms\n",
      "Speed: 2.0ms preprocess, 65.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 65.7ms\n",
      "Speed: 2.0ms preprocess, 65.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 65.6ms\n",
      "Speed: 1.0ms preprocess, 65.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.1ms\n",
      "Speed: 1.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.2ms\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 7.62m\n",
      "Average distance: 7.61904761904762\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 19.0\n",
      "Speed vector: Vector3D(x=5.288386, y=0.015087, z=-0.000423)\n",
      "Distance (front camera): 7.62m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 65.7ms\n",
      "Speed: 2.0ms preprocess, 65.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 102.6ms\n",
      "Speed: 2.0ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.6ms\n",
      "Speed: 2.0ms preprocess, 63.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 6.81m\n",
      "Average distance: 6.808510638297873\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 24.0\n",
      "Speed vector: Vector3D(x=6.584070, y=0.014874, z=-0.000060)\n",
      "Distance (front camera): 6.81m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 72.4ms\n",
      "Speed: 1.0ms preprocess, 72.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 70.7ms\n",
      "Speed: 2.0ms preprocess, 70.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 6.27m\n",
      "Average distance: 6.274509803921569\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 29.0\n",
      "Speed vector: Vector3D(x=8.100813, y=0.024004, z=0.000006)\n",
      "Distance (front camera): 6.27m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 78.7ms\n",
      "Speed: 2.0ms preprocess, 78.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 75.2ms\n",
      "Speed: 1.0ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 91.7ms\n",
      "Speed: 2.0ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 5.16m\n",
      "Average distance: 5.161290322580646\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 30.0\n",
      "Speed vector: Vector3D(x=8.411262, y=0.029359, z=0.000000)\n",
      "Distance (front camera): 5.16m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 88.2ms\n",
      "Speed: 2.5ms preprocess, 88.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 80.3ms\n",
      "Speed: 2.0ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 70.2ms\n",
      "Speed: 2.0ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 69.2ms\n",
      "Speed: 0.0ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 65.1ms\n",
      "Speed: 1.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 5.82m\n",
      "Distance (front camera): 3.95m\n",
      "Average distance: 4.510886644219978\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 25.0\n",
      "Speed vector: Vector3D(x=6.842443, y=0.014561, z=-0.000001)\n",
      "Distance (front camera): 3.95m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 72.2ms\n",
      "Speed: 2.0ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 66.0ms\n",
      "Speed: 1.0ms preprocess, 66.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 98.0ms\n",
      "Speed: 1.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 65.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 3.05m\n",
      "Average distance: 3.0476190476190483\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 21.0\n",
      "Speed vector: Vector3D(x=5.889053, y=0.216914, z=0.000001)\n",
      "Distance (right camera): 3.05m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.5ms preprocess, 65.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.1ms\n",
      "Speed: 2.0ms preprocess, 64.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 3.02m\n",
      "Average distance: 3.0188679245283025\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 22.0\n",
      "Speed vector: Vector3D(x=5.894229, y=1.252178, z=-0.000001)\n",
      "Distance (right camera): 3.02m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 62.9ms\n",
      "Speed: 2.5ms preprocess, 62.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 66.2ms\n",
      "Speed: 2.0ms preprocess, 66.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 65.7ms\n",
      "Speed: 1.0ms preprocess, 65.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 62.2ms\n",
      "Speed: 1.3ms preprocess, 62.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 2.74m\n",
      "Average distance: 2.7350427350427355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 29.0\n",
      "Speed vector: Vector3D(x=6.840111, y=4.487516, z=0.000000)\n",
      "Distance (right camera): 2.74m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 66.6ms\n",
      "Speed: 2.5ms preprocess, 66.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 63.6ms\n",
      "Speed: 2.0ms preprocess, 63.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.2ms\n",
      "Speed: 1.6ms preprocess, 74.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 1.89m\n",
      "Average distance: 1.8934911242603554\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 31.0\n",
      "Speed vector: Vector3D(x=5.706732, y=6.284819, z=-0.000000)\n",
      "Distance (right camera): 1.89m\n",
      "Collision with vehicle.bh.crossbike\n",
      "Impulse: Vector3D(x=23.368059, y=-23.662949, z=-20.263149)\n",
      "Location: Location(x=-54.570629, y=31.177374, z=0.042766)\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n",
      "Collision with vehicle.bh.crossbike\n",
      "Impulse: Vector3D(x=4.999840, y=-4.596857, z=-0.232079)\n",
      "Location: Location(x=-54.208008, y=31.590912, z=0.042978)\n",
      "Collision with vehicle.bh.crossbike\n",
      "Impulse: Vector3D(x=0.482049, y=-0.407427, z=-0.022235)\n",
      "Location: Location(x=-53.861614, y=32.033489, z=0.043418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 68.3ms\n",
      "Speed: 1.5ms preprocess, 68.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 67.0ms\n",
      "Speed: 2.0ms preprocess, 67.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.1ms\n",
      "Speed: 2.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 0.94m\n",
      "Average distance: 0.9384164222873902\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "curr_wp = 5\n",
    "collision_happened = False\n",
    "quitLoop = False\n",
    "\n",
    "while curr_wp<len(route)-1:\n",
    "    world.tick()\n",
    "    \n",
    "    while vehicle.get_transform().location.distance(route[curr_wp][0].transform.location) < 5:\n",
    "        curr_wp += 1\n",
    "\n",
    "    #Setup the object detection\n",
    "    rightframe1 = rightcamera1_data['image']\n",
    "    rightframe2 = rightcamera2_data['image']\n",
    "    frontframe1 = frontcamera1_data['image']\n",
    "    frontframe2 = frontcamera2_data['image']\n",
    "\n",
    "    # frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGRA2GRAY)\n",
    "    # frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "\n",
    "    print(\"rightframe1 dtype:\", rightframe1.dtype)\n",
    "    print(\"rightframe2 dtype:\", rightframe2.dtype)\n",
    "    print(\"frontframe1 dtype:\", frontframe1.dtype)\n",
    "    print(\"frontframe2 dtype:\", frontframe2.dtype)\n",
    "\n",
    "    # Convert RGB image from BGRA to BGR\n",
    "    rightframe1 = cv2.cvtColor(rightframe1, cv2.COLOR_BGRA2BGR)\n",
    "    rightframe2 = cv2.cvtColor(rightframe2, cv2.COLOR_BGRA2BGR)\n",
    "    frontframe1 = cv2.cvtColor(frontframe1, cv2.COLOR_BGRA2BGR)\n",
    "    frontframe2 = cv2.cvtColor(frontframe2, cv2.COLOR_BGRA2BGR)\n",
    "    #computeDepthMapSGBM(frame1_gray, frame2_gray)\n",
    "    # Run the object detection model on the RGB frame\n",
    "    results_right1 = model(rightframe1)\n",
    "    results_right2 = model(rightframe2)\n",
    "    \n",
    "    results_front1 = model(frontframe1)\n",
    "    results_front2 = model(frontframe2)\n",
    "    \n",
    "    bicycles_right1 = []\n",
    "    bicycles_right2 = []\n",
    "    bicycles_front1 = []\n",
    "    bicycles_front2 = []\n",
    "\n",
    "\n",
    "\n",
    "    for result in results_right1:\n",
    "        for box in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)  # x-center of the bicycle\n",
    "            center_y = int((y1 + y2) / 2)  # y-center of the bicycle\n",
    "            bicycles_right1.append((center_x, center_y))\n",
    "            conf = box.conf[0]            # Confidence score\n",
    "            cls = box.cls[0]\n",
    "            cv2.rectangle(rightframe1, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(rightframe1, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            #break\n",
    "              # Bounding box coordinates\n",
    "    \n",
    "    for result in results_right2:\n",
    "        for box2 in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box2.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "            bicycles_right2.append((center_x, center_y))\n",
    "            conf = box2.conf[0]            # Confidence score\n",
    "            cls = box2.cls[0]\n",
    "\n",
    "            cv2.rectangle(rightframe2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(rightframe2, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    for result in results_front1:\n",
    "        for box2 in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box2.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "            bicycles_front1.append((center_x, center_y))\n",
    "            conf = box2.conf[0]            # Confidence score\n",
    "            cls = box2.cls[0]\n",
    "\n",
    "            cv2.rectangle(frontframe1, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(frontframe1, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    for result in results_front2:\n",
    "        for box2 in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box2.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "            bicycles_front2.append((center_x, center_y))\n",
    "            conf = box2.conf[0]            # Confidence score\n",
    "            cls = box2.cls[0]\n",
    "\n",
    "            cv2.rectangle(frontframe2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(frontframe2, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    matched_bicycles_with_distances_right = match_bicycles_between_left_right(bicycles_right1, bicycles_right2)\n",
    "    matched_bicycles_with_distances_front = match_bicycles_between_left_right(bicycles_front1, bicycles_front2)\n",
    "    # Display distance for each matched bicycle on the left frame\n",
    "    \n",
    "    distance_front = 0\n",
    "    distance_right = 0\n",
    "\n",
    "\n",
    "    for (left_bicycle, distance) in matched_bicycles_with_distances_right:\n",
    "        left_x, left_y = left_bicycle\n",
    "        distance_label = f\"Distance (right camera): {distance:.2f}m\"\n",
    "        distance_right = distance\n",
    "        cv2.putText(rightframe1, distance_label, (left_x, left_y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        print(distance_label)\n",
    "\n",
    "\n",
    "    for (left_bicycle, distance) in matched_bicycles_with_distances_front:\n",
    "        left_x, left_y = left_bicycle\n",
    "        distance_front = distance\n",
    "        distance_label = f\"Distance (front camera): {distance:.2f}m\"\n",
    "        cv2.putText(frontframe1, distance_label, (left_x, left_y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        print(distance_label)\n",
    "\n",
    "    if distance_front > 0 and distance_right > 0:\n",
    "        min_distance = np.min([distance_front, distance_right])\n",
    "        max_distance = np.max([distance_front, distance_right])\n",
    "\n",
    "        avg_distance = (min_distance*0.7 + max_distance*0.3)\n",
    "    elif distance_front == 0:\n",
    "        avg_distance = distance_right\n",
    "    elif distance_right == 0:\n",
    "        avg_distance = distance_front\n",
    "    else:\n",
    "        avg_distance = 1000\n",
    "    \n",
    "    print(f\"Average distance: {avg_distance}\")\n",
    "\n",
    "    #Estimate the throttle \n",
    "    predicted_angle = get_angle(vehicle, route[curr_wp][0])\n",
    "    v = vehicle.get_velocity()\n",
    "    speed = round(3.6*math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n",
    "    estimated_throttle = maintain_speed(speed)\n",
    "\n",
    "\n",
    "    #Setup the steering angle\n",
    "    if predicted_angle < -300:\n",
    "        predicted_angle = predicted_angle+360\n",
    "    elif predicted_angle > 300:\n",
    "        predicted_angle = predicted_angle - 360\n",
    "    steering_angle = predicted_angle\n",
    "\n",
    "    if predicted_angle < -MAX_STEER_DEGREES:\n",
    "        steering_angle = -MAX_STEER_DEGREES\n",
    "    elif predicted_angle>MAX_STEER_DEGREES:\n",
    "        steering_angle = MAX_STEER_DEGREES\n",
    "    \n",
    "    steering_angle = steering_angle/75\n",
    "\n",
    "\n",
    "    #Apply the vehicle control to each of the two vehicles\n",
    "    bicycle.apply_control(carla.VehicleControl(throttle=1))\n",
    "    vehicle.apply_control(carla.VehicleControl(throttle = estimated_throttle, steer = steering_angle))\n",
    "    \n",
    "    # speed_text = f\"{speed} km/h\"\n",
    "    # cv2.putText(frame1, speed_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # cv2.imshow('Front1 camera',frontframe1)\n",
    "    # cv2.imshow(\"camera2\", rightframe1)\n",
    "    # Exit loop on 'q' key press\n",
    "    if cv2.waitKey(1) == ord('q') or collision_happened:\n",
    "        break\n",
    "\n",
    "    print('------------------')\n",
    "    print('These are the parameters that we might need')\n",
    "    print(f\"speed: {speed}\")\n",
    "    print(f\"Speed vector: {v}\")\n",
    "    try:\n",
    "        print(distance_label)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "    #Check if a collision happenned\n",
    "    if collision_happened:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows() \n",
    "vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "bicycle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "destroy()\n",
    "bicycleorigin()\n",
    "carorigin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
