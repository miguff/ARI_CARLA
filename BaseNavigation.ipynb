{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('F:\\CARLA\\Windows\\CARLA_0.9.15\\PythonAPI\\carla') # tweak to where you put carla\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "world = client.get_world()\n",
    "\n",
    "blueprints = [bp for bp in world.get_blueprint_library().filter('*')]\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destroy():#Destroying the existing things\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawPointsFor30Sec(world, spawn_points):\n",
    "    drawn_points = []\n",
    "    for index, waypoint in enumerate(spawn_points):\n",
    "        # Draw a string with an ID at the location of each spawn point\n",
    "        point_id = f'ID: {index}'\n",
    "        point = world.debug.draw_string(\n",
    "            waypoint.location,\n",
    "            point_id,\n",
    "            draw_shadow=False,\n",
    "            color=carla.Color(r=255, g=255, b=255),\n",
    "            life_time=30,  # Set to 0 to make it persist indefinitely\n",
    "            persistent_lines=True\n",
    "        )\n",
    "        drawn_points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawPointsFor30Sec(world, spawn_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the bicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicycleorigin():\n",
    "    global bicycle\n",
    "    bicycle_bp = world.get_blueprint_library().filter('*crossbike*')\n",
    "    bicycle_start_point = spawn_points[1]\n",
    "\n",
    "    bicycle = world.try_spawn_actor(bicycle_bp[0], bicycle_start_point)\n",
    "    bicyclepos = carla.Transform(bicycle_start_point.location + carla.Location(x=-3, y=3.5))\n",
    "    bicycle.set_transform(bicyclepos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carorigin():\n",
    "    global vehicle, vehicle_start_point\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*mini*')\n",
    "    vehicle_start_point = spawn_points[94]\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], vehicle_start_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Car speed and etc specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = None\n",
    "bicycle = None\n",
    "vehicle_start_point = None\n",
    "destroy()\n",
    "bicycleorigin()\n",
    "carorigin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFERRED_SPEED = 30 #km/h\n",
    "SPEED_THRESHOLD = 2 #When we close to the required speed, it drops the throttle\n",
    "MAX_STEER_DEGREES = 40\n",
    "\n",
    "#Params for displaying text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "org = (30, 30) # This is for current speed\n",
    "org2 = (30, 50) #This is for future steering angle\n",
    "org3 = (30, 70) #this is for future telemetry\n",
    "org4 = (30, 90) #this is for future telemetry\n",
    "org5 = (30, 110) #this is for future telemetry\n",
    "fontscale = 0.5\n",
    "color = (255, 255, 255)\n",
    "tickness = 1\n",
    "\n",
    "def maintain_speed(s: float) -> float:\n",
    "    \n",
    "    if s >= PREFERRED_SPEED:\n",
    "        return 0\n",
    "    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n",
    "        return 0.8\n",
    "    else:\n",
    "        return 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the collision detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_collision(event):\n",
    "    # Extract collision data\n",
    "    global collision_happened\n",
    "    other_actor = event.other_actor\n",
    "    impulse = event.normal_impulse\n",
    "    collision_location = event.transform.location\n",
    "    print(f\"Collision with {other_actor.type_id}\")\n",
    "    print(f\"Impulse: {impulse}\")\n",
    "    print(f\"Location: {collision_location}\")\n",
    "    collision_happened = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_detector_bp = world.get_blueprint_library().find('sensor.other.collision')\n",
    "collision_sensor = world.spawn_actor(\n",
    "        collision_detector_bp,\n",
    "        carla.Transform(),\n",
    "        attach_to=vehicle\n",
    "    )\n",
    "collision_sensor.listen(lambda event: process_collision(event))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the GlobalRoutePlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetid = 27\n",
    "targetPoint = spawn_points[targetid]\n",
    "\n",
    "point_A = vehicle_start_point.location\n",
    "point_B = targetPoint.location\n",
    "\n",
    "\n",
    "sampling_resolution = 1\n",
    "grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "\n",
    "route = grp.trace_route(point_A, point_B)\n",
    "for waypoint in route:\n",
    "    world.debug.draw_string(waypoint[0].transform.location, '^', draw_shadow=False,\n",
    "                            color=carla.Color(r=0, g=0, b=255), life_time=600.0,\n",
    "                            persistent_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between(v1, v2):\n",
    "    return math.degrees(np.arctan2(v1[1], v1[0]) - np.arctan2(v2[1], v2[0]))\n",
    "\n",
    "def get_angle(car, wp):\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "\n",
    "\n",
    "    #vector to waypoint\n",
    "    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "\n",
    "\n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = angle_between((x,y), (car_vector.x, car_vector.y))\n",
    "\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Camera sensor and the YOLO algoritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mihge\\anaconda3\\envs\\carla-sim\\lib\\site-packages\\requests\\__init__.py:114: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning,\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "#setup the camera\n",
    "CAMERA_POS_Z = 1.5 \n",
    "CAMERA1_POS_X = 0\n",
    "CAMERA2_POS_X = 1\n",
    "CAMERA1_POS_Y = 0.5\n",
    "CAMERA2_POS_Y = 1.5\n",
    "\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.14 on Windows\n",
    "camera_bp.set_attribute('image_size_y', '360')\n",
    "\n",
    "\n",
    "rightcamera1_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA1_POS_X, y = CAMERA1_POS_Y), carla.Rotation(yaw=90))\n",
    "rightcamera1 = world.spawn_actor(camera_bp,rightcamera1_init_trans,attach_to=vehicle)\n",
    "\n",
    "rightcamera2_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA2_POS_X, y = CAMERA1_POS_Y), carla.Rotation(yaw=90))\n",
    "rightcamera2 = world.spawn_actor(camera_bp,rightcamera2_init_trans,attach_to=vehicle)\n",
    "\n",
    "frontcamera1_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA1_POS_X, y = CAMERA1_POS_Y))\n",
    "frontcamera1 = world.spawn_actor(camera_bp,frontcamera1_init_trans,attach_to=vehicle)\n",
    "\n",
    "frontcamera2_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA1_POS_X, y = CAMERA2_POS_Y))\n",
    "frontcamera2 = world.spawn_actor(camera_bp,frontcamera2_init_trans,attach_to=vehicle)\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "rightcamera1_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "rightcamera2_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "frontcamera1_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "frontcamera2_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "# this actually opens a live stream from the camera\n",
    "rightcamera1.listen(lambda image: camera_callback(image,rightcamera1_data))\n",
    "rightcamera2.listen(lambda image: camera_callback(image,rightcamera2_data))\n",
    "frontcamera1.listen(lambda image: camera_callback(image,frontcamera1_data))\n",
    "frontcamera2.listen(lambda image: camera_callback(image,frontcamera2_data))\n",
    "model = YOLO(\"best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def match_bicycles_between_left_right(bicycles_left: list, bicycles_right: list):\n",
    "    image_w = 640  # Image width\n",
    "    fov = 90  # Field of view in degrees\n",
    "    baseline = 1  # Baseline distance in meters\n",
    "    focal_length = image_w / (2 * math.tan(math.radians(fov / 2)))  # Focal length in pixels\n",
    "\n",
    "    \n",
    "    y_threshold = 20  # pixels, adjust based on image scale\n",
    "    matched_bicycles_with_distances = []\n",
    "\n",
    "    for left_bicycle in bicycles_left:\n",
    "        left_x, left_y = left_bicycle\n",
    "        closest_bicycle = None\n",
    "        min_dist = float('inf')\n",
    "\n",
    "        for right_bicycle in bicycles_right:\n",
    "            right_x, right_y = right_bicycle\n",
    "            # Check if the y-coordinates are similar\n",
    "            if abs(left_y - right_y) < y_threshold:\n",
    "                # Calculate the distance (disparity)\n",
    "                dist = abs(left_x - right_x)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_bicycle = right_bicycle\n",
    "\n",
    "        # If a match was found, calculate depth and add to list\n",
    "        if closest_bicycle:\n",
    "            right_x, _ = closest_bicycle\n",
    "            disparity = abs(left_x - right_x)\n",
    "            depth = (focal_length * baseline) / disparity if disparity != 0 else float('inf')\n",
    "            matched_bicycles_with_distances.append((left_bicycle, depth))\n",
    "\n",
    "    return matched_bicycles_with_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 112.0ms\n",
      "Speed: 2.5ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.7ms\n",
      "Speed: 2.0ms preprocess, 84.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 84.2ms\n",
      "Speed: 2.6ms preprocess, 84.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 84.7ms\n",
      "Speed: 2.0ms preprocess, 84.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.8ms\n",
      "Speed: 2.5ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.14m\n",
      "Average distance: 9.142857142857144\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=0.000000, z=0.000000)\n",
      "Distance (front camera): 9.14m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 90.4ms\n",
      "Speed: 2.0ms preprocess, 90.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 86.7ms\n",
      "Speed: 2.5ms preprocess, 86.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 82.5ms\n",
      "Speed: 1.0ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.4ms\n",
      "Speed: 2.0ms preprocess, 89.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.41m\n",
      "Average distance: 9.411764705882355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 0.0\n",
      "Speed vector: Vector3D(x=0.000000, y=0.000000, z=0.000012)\n",
      "Distance (front camera): 9.41m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 88.3ms\n",
      "Speed: 2.0ms preprocess, 88.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 84.9ms\n",
      "Speed: 1.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 94.4ms\n",
      "Speed: 3.0ms preprocess, 94.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.7ms\n",
      "Speed: 2.5ms preprocess, 86.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.41m\n",
      "Average distance: 9.411764705882355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 6.0\n",
      "Speed vector: Vector3D(x=1.618706, y=0.005099, z=0.000413)\n",
      "Distance (front camera): 9.41m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 75.0ms\n",
      "Speed: 2.0ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.8ms\n",
      "Speed: 1.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.8ms\n",
      "Speed: 2.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 9.41m\n",
      "Average distance: 9.411764705882355\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 10.0\n",
      "Speed vector: Vector3D(x=2.743161, y=0.007895, z=-0.000097)\n",
      "Distance (front camera): 9.41m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 77.4ms\n",
      "Speed: 1.0ms preprocess, 77.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 76.0ms\n",
      "Speed: 1.5ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 73.7ms\n",
      "Speed: 2.0ms preprocess, 73.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 7.80m\n",
      "Average distance: 7.804878048780489\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 16.0\n",
      "Speed vector: Vector3D(x=4.398980, y=0.012005, z=0.000376)\n",
      "Distance (front camera): 7.80m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 75.2ms\n",
      "Speed: 1.0ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 75.8ms\n",
      "Speed: 1.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.2ms\n",
      "Speed: 1.0ms preprocess, 76.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 7.44m\n",
      "Average distance: 7.441860465116281\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 20.0\n",
      "Speed vector: Vector3D(x=5.526223, y=0.015100, z=-0.000429)\n",
      "Distance (front camera): 7.44m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 75.3ms\n",
      "Speed: 1.5ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Bicycles, 76.3ms\n",
      "Speed: 1.0ms preprocess, 76.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 93.3ms\n",
      "Speed: 1.0ms preprocess, 93.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.8ms\n",
      "Speed: 1.0ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 6.96m\n",
      "Average distance: 6.956521739130436\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 23.0\n",
      "Speed vector: Vector3D(x=6.351968, y=0.016969, z=-0.000064)\n",
      "Distance (front camera): 6.96m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 77.7ms\n",
      "Speed: 1.0ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 75.7ms\n",
      "Speed: 2.0ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 71.8ms\n",
      "Speed: 2.0ms preprocess, 71.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 5.82m\n",
      "Average distance: 5.818181818181819\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 30.0\n",
      "Speed vector: Vector3D(x=8.283188, y=0.024381, z=0.000004)\n",
      "Distance (front camera): 5.82m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 76.8ms\n",
      "Speed: 1.0ms preprocess, 76.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 73.8ms\n",
      "Speed: 1.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 73.3ms\n",
      "Speed: 2.5ms preprocess, 73.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.9ms\n",
      "Speed: 2.0ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 73.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (front camera): 5.00m\n",
      "Average distance: 5.000000000000001\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 28.0\n",
      "Speed vector: Vector3D(x=7.841578, y=0.020350, z=0.000002)\n",
      "Distance (front camera): 5.00m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 77.3ms\n",
      "Speed: 1.0ms preprocess, 77.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.3ms\n",
      "Speed: 2.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 5.52m\n",
      "Distance (front camera): 3.60m\n",
      "Average distance: 4.172026346377374\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 22.0\n",
      "Speed vector: Vector3D(x=5.999924, y=0.015864, z=-0.000001)\n",
      "Distance (front camera): 3.60m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 75.1ms\n",
      "Speed: 2.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.3ms\n",
      "Speed: 1.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 73.5ms\n",
      "Speed: 2.5ms preprocess, 73.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.2ms\n",
      "Speed: 1.5ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 2.91m\n",
      "Average distance: 2.9090909090909096\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 21.0\n",
      "Speed vector: Vector3D(x=5.795209, y=0.060793, z=-0.000001)\n",
      "Distance (right camera): 2.91m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 75.2ms\n",
      "Speed: 1.5ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.8ms\n",
      "Speed: 2.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 75.3ms\n",
      "Speed: 1.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 75.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 2.94m\n",
      "Average distance: 2.935779816513762\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 28.0\n",
      "Speed vector: Vector3D(x=7.670513, y=1.299909, z=-0.000002)\n",
      "Distance (right camera): 2.94m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.3ms\n",
      "Speed: 1.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 71.3ms\n",
      "Speed: 1.5ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 2.62m\n",
      "Average distance: 2.6229508196721314\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 28.0\n",
      "Speed vector: Vector3D(x=7.020891, y=3.634911, z=0.000002)\n",
      "Distance (right camera): 2.62m\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Bicycle, 75.8ms\n",
      "Speed: 1.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.3ms\n",
      "Speed: 1.5ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 72.3ms\n",
      "Speed: 1.0ms preprocess, 72.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Bicycle, 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance (right camera): 2.08m\n",
      "Average distance: 2.077922077922078\n",
      "------------------\n",
      "These are the parameters that we might need\n",
      "speed: 27.0\n",
      "Speed vector: Vector3D(x=5.022538, y=5.732505, z=0.000001)\n",
      "Distance (right camera): 2.08m\n",
      "Collision with vehicle.bh.crossbike\n",
      "Impulse: Vector3D(x=-26.924513, y=26.875227, z=23.184025)\n",
      "Location: Location(x=-54.664589, y=30.812361, z=0.042800)\n",
      "rightframe1 dtype: uint8\n",
      "rightframe2 dtype: uint8\n",
      "frontframe1 dtype: uint8\n",
      "frontframe2 dtype: uint8\n",
      "Collision with vehicle.bh.crossbike\n",
      "Impulse: Vector3D(x=-2.456024, y=2.242962, z=0.114931)\n",
      "Location: Location(x=-54.175652, y=31.396484, z=0.043165)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 74.3ms\n",
      "Speed: 1.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.2ms\n",
      "Speed: 2.0ms preprocess, 76.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collision with vehicle.bh.crossbike\n",
      "Impulse: Vector3D(x=-3.696645, y=3.013654, z=0.167715)\n",
      "Location: Location(x=-53.913967, y=31.756874, z=0.043308)\n",
      "Average distance: 0\n"
     ]
    }
   ],
   "source": [
    "curr_wp = 5\n",
    "collision_happened = False\n",
    "quitLoop = False\n",
    "\n",
    "while curr_wp<len(route)-1:\n",
    "    world.tick()\n",
    "    \n",
    "    while vehicle.get_transform().location.distance(route[curr_wp][0].transform.location) < 5:\n",
    "        curr_wp += 1\n",
    "\n",
    "    #Setup the object detection\n",
    "    rightframe1 = rightcamera1_data['image']\n",
    "    rightframe2 = rightcamera2_data['image']\n",
    "    frontframe1 = frontcamera1_data['image']\n",
    "    frontframe2 = frontcamera2_data['image']\n",
    "\n",
    "    # frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGRA2GRAY)\n",
    "    # frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "\n",
    "    print(\"rightframe1 dtype:\", rightframe1.dtype)\n",
    "    print(\"rightframe2 dtype:\", rightframe2.dtype)\n",
    "    print(\"frontframe1 dtype:\", frontframe1.dtype)\n",
    "    print(\"frontframe2 dtype:\", frontframe2.dtype)\n",
    "\n",
    "    # Convert RGB image from BGRA to BGR\n",
    "    rightframe1 = cv2.cvtColor(rightframe1, cv2.COLOR_BGRA2BGR)\n",
    "    rightframe2 = cv2.cvtColor(rightframe2, cv2.COLOR_BGRA2BGR)\n",
    "    frontframe1 = cv2.cvtColor(frontframe1, cv2.COLOR_BGRA2BGR)\n",
    "    frontframe2 = cv2.cvtColor(frontframe2, cv2.COLOR_BGRA2BGR)\n",
    "    #computeDepthMapSGBM(frame1_gray, frame2_gray)\n",
    "    # Run the object detection model on the RGB frame\n",
    "    results_right1 = model(rightframe1)\n",
    "    results_right2 = model(rightframe2)\n",
    "    \n",
    "    results_front1 = model(frontframe1)\n",
    "    results_front2 = model(frontframe2)\n",
    "    \n",
    "    bicycles_right1 = []\n",
    "    bicycles_right2 = []\n",
    "    bicycles_front1 = []\n",
    "    bicycles_front2 = []\n",
    "\n",
    "\n",
    "\n",
    "    for result in results_right1:\n",
    "        for box in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)  # x-center of the bicycle\n",
    "            center_y = int((y1 + y2) / 2)  # y-center of the bicycle\n",
    "            bicycles_right1.append((center_x, center_y))\n",
    "            conf = box.conf[0]            # Confidence score\n",
    "            cls = box.cls[0]\n",
    "            cv2.rectangle(rightframe1, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(rightframe1, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            #break\n",
    "              # Bounding box coordinates\n",
    "    \n",
    "    for result in results_right2:\n",
    "        for box2 in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box2.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "            bicycles_right2.append((center_x, center_y))\n",
    "            conf = box2.conf[0]            # Confidence score\n",
    "            cls = box2.cls[0]\n",
    "\n",
    "            cv2.rectangle(rightframe2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(rightframe2, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    for result in results_front1:\n",
    "        for box2 in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box2.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "            bicycles_front1.append((center_x, center_y))\n",
    "            conf = box2.conf[0]            # Confidence score\n",
    "            cls = box2.cls[0]\n",
    "\n",
    "            cv2.rectangle(frontframe1, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(frontframe1, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    for result in results_front2:\n",
    "        for box2 in result.boxes:\n",
    "            # Extract box coordinates and other details\n",
    "            x1, y1, x2, y2 = box2.xyxy[0]\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "            bicycles_front2.append((center_x, center_y))\n",
    "            conf = box2.conf[0]            # Confidence score\n",
    "            cls = box2.cls[0]\n",
    "\n",
    "            cv2.rectangle(frontframe2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "            cv2.putText(frontframe2, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    matched_bicycles_with_distances_right = match_bicycles_between_left_right(bicycles_right1, bicycles_right2)\n",
    "    matched_bicycles_with_distances_front = match_bicycles_between_left_right(bicycles_front1, bicycles_front2)\n",
    "    # Display distance for each matched bicycle on the left frame\n",
    "    \n",
    "    distance_front = 0\n",
    "    distance_right = 0\n",
    "\n",
    "\n",
    "    for (left_bicycle, distance) in matched_bicycles_with_distances_right:\n",
    "        left_x, left_y = left_bicycle\n",
    "        distance_label = f\"Distance (right camera): {distance:.2f}m\"\n",
    "        distance_right = distance\n",
    "        cv2.putText(rightframe1, distance_label, (left_x, left_y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        print(distance_label)\n",
    "\n",
    "\n",
    "    for (left_bicycle, distance) in matched_bicycles_with_distances_front:\n",
    "        left_x, left_y = left_bicycle\n",
    "        distance_front = distance\n",
    "        distance_label = f\"Distance (front camera): {distance:.2f}m\"\n",
    "        cv2.putText(frontframe1, distance_label, (left_x, left_y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        print(distance_label)\n",
    "\n",
    "    if distance_front > 0 and distance_right > 0:\n",
    "        min_distance = np.min([distance_front, distance_right])\n",
    "        max_distance = np.max([distance_front, distance_right])\n",
    "\n",
    "        avg_distance = (min_distance*0.7 + max_distance*0.3)\n",
    "    elif distance_front == 0:\n",
    "        avg_distance = distance_right\n",
    "    elif distance_right == 0:\n",
    "        avg_distance = distance_front\n",
    "    else:\n",
    "        avg_distance = 1000\n",
    "    \n",
    "    print(f\"Average distance: {avg_distance}\")\n",
    "\n",
    "    #Estimate the throttle \n",
    "    predicted_angle = get_angle(vehicle, route[curr_wp][0])\n",
    "    v = vehicle.get_velocity()\n",
    "    speed = round(3.6*math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n",
    "    estimated_throttle = maintain_speed(speed)\n",
    "\n",
    "\n",
    "    #Setup the steering angle\n",
    "    if predicted_angle < -300:\n",
    "        predicted_angle = predicted_angle+360\n",
    "    elif predicted_angle > 300:\n",
    "        predicted_angle = predicted_angle - 360\n",
    "    steering_angle = predicted_angle\n",
    "\n",
    "    if predicted_angle < -MAX_STEER_DEGREES:\n",
    "        steering_angle = -MAX_STEER_DEGREES\n",
    "    elif predicted_angle>MAX_STEER_DEGREES:\n",
    "        steering_angle = MAX_STEER_DEGREES\n",
    "    \n",
    "    steering_angle = steering_angle/75\n",
    "\n",
    "\n",
    "    #Apply the vehicle control to each of the two vehicles\n",
    "    bicycle.apply_control(carla.VehicleControl(throttle=1))\n",
    "    vehicle.apply_control(carla.VehicleControl(throttle = estimated_throttle, steer = steering_angle))\n",
    "    \n",
    "    # speed_text = f\"{speed} km/h\"\n",
    "    # cv2.putText(frame1, speed_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    #cv2.imshow('Front1 camera',frontframe1)\n",
    "    cv2.imshow(\"camera2\", rightframe1)\n",
    "    # Exit loop on 'q' key press\n",
    "    if cv2.waitKey(1) == ord('q') or collision_happened:\n",
    "        break\n",
    "\n",
    "    print('------------------')\n",
    "    print('These are the parameters that we might need')\n",
    "    print(f\"speed: {speed}\")\n",
    "    print(f\"Speed vector: {v}\")\n",
    "    try:\n",
    "        print(distance_label)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "    #Check if a collision happenned\n",
    "    if collision_happened:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows() \n",
    "vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "bicycle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "destroy()\n",
    "bicycleorigin()\n",
    "carorigin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
